<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>視覚障がい者向け風景案内</title>
<style>
 body {
   margin: 0;
   font-family: sans-serif;
   background: #111;
   color: #fff;
   overflow: hidden;
 }
 #container {
   position: relative;
   width: 100vw;
   height: 100vh;
   display: flex;
   flex-direction: column;
   justify-content: center;
   align-items: center;
 }
 video {
   position: absolute;
   width: 100%;
   height: 100%;
   object-fit: cover;
   z-index: 1;
 }
 #overlay {
   position: absolute;
   bottom: 0;
   width: 100%;
   padding: 20px;
   background: rgba(0,0,0,0.5);
   z-index: 2;
   font-size: 1.2rem;
   line-height: 1.6;
 }
 #keyModal {
   position: fixed;
   top: 0;
   left: 0;
   width: 100%;
   height: 100%;
   background: rgba(0,0,0,0.8);
   color: #fff;
   display: flex;
   justify-content: center;
   align-items: center;
   flex-direction: column;
   z-index: 10;
 }
 #keyModal input {
   width: 80%;
   padding: 12px;
   border-radius: 10px;
   margin-bottom: 20px;
   font-size: 1.1rem;
 }
 #keyModal button {
   padding: 12px 20px;
   font-size: 1.1rem;
   border-radius: 10px;
 }
</style>
</head>
<body>
<div id="keyModal">
  <h2>ChatGPT API Key を入力してください</h2>
  <input id="apiKeyInput" placeholder="sk-..." />
  <button onclick="saveKey()">保存して開始</button>
</div>
<div id="container" onclick="captureAndDescribe()">
  <video id="camera" autoplay playsinline></video>
  <div id="overlay">画面をタッチして風景を解析します…</div>
</div>
<script>
let apiKey = "";
let stream;
let speech = window.speechSynthesis;

async function loadKey() {
  const db = await openDB();
  const key = await db.get('kv','apiKey');
  if (key) {
    apiKey = key;
    document.getElementById('keyModal').style.display = 'none';
    startCamera();
  }
}

async function saveKey() {
  const v = document.getElementById('apiKeyInput').value.trim();
  if (!v) return;
  const db = await openDB();
  await db.put('kv', v, 'apiKey');
  apiKey = v;
  document.getElementById('keyModal').style.display = 'none';
  startCamera();
}

function openDB() {
  return new Promise((resolve, reject)=>{
    const req = indexedDB.open('visionDB',1);
    req.onupgradeneeded = ()=>{
      const db = req.result;
      if (!db.objectStoreNames.contains('kv')) db.createObjectStore('kv');
    };
    req.onsuccess = ()=> resolve(req.result);
    req.onerror = ()=> reject(req.error);
  });
}

async function startCamera() {
  stream = await navigator.mediaDevices.getUserMedia({ video: true });
  const video = document.getElementById('camera');
  video.srcObject = stream;
}

async function captureAndDescribe() {
  if (!apiKey) return;
  const video = document.getElementById('camera');
  const canvas = document.createElement('canvas');
  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;
  const ctx = canvas.getContext('2d');
  ctx.drawImage(video,0,0);
  const dataUrl = canvas.toDataURL('image/jpeg');

  const overlay = document.getElementById('overlay');
  overlay.textContent = '解析中…';
  speak('解析します');

  const response = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "Authorization": `Bearer ${apiKey}`
    },
    body: JSON.stringify({
      model: "gpt-4o-mini",
      messages: [
        { role: "system", content: "あなたは視覚障害者向けに、周囲の状況を丁寧で優しい日本語で説明するアシスタントです。"},
        { role: "user", content: [
          { type: "text", text: "この画像に写っている光景を、視覚障害者向けに分かりやすく説明してください。"},
          { type: "image_url", image_url: dataUrl }
        ] }
      ]
    })
  });

  const json = await response.json();
  let text = json.choices?.[0]?.message?.content || "情報を取得できませんでした";
  overlay.textContent = text;
  speak(text);
}

function speak(text) {
  if (!speech) return;
  speech.cancel();
  const ut = new SpeechSynthesisUtterance(text);
  ut.lang = 'ja-JP';
  speech.speak(ut);
}

loadKey();
</script>
</body>
</html>
