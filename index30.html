<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>視覚障がい者向け風景案内</title>
<style>
 body {
   margin: 0;
   font-family: sans-serif;
   background: #111;
   color: #fff;
   overflow: hidden;
 }
 #container {
   position: relative;
   width: 100vw;
   height: 100vh;
   display: flex;
   flex-direction: column;
   justify-content: center;
   align-items: center;
 }
 video {
   position: absolute;
   width: 100%;
   height: 100%;
   object-fit: cover;
   z-index: 1;
 }
 #overlay {
   position: absolute;
   bottom: 0;
   width: 100%;
   padding: 20px;
   background: rgba(0,0,0,0.5);
   z-index: 2;
   font-size: 1.2rem;
   line-height: 1.6;
 }
 #keyModal {
   position: fixed;
   top: 0;
   left: 0;
   width: 100%;
   height: 100%;
   background: rgba(0,0,0,0.8);
   color: #fff;
   display: flex;
   justify-content: center;
   align-items: center;
   flex-direction: column;
   z-index: 10;
 }
 #keyModal input {
   width: 80%;
   padding: 12px;
   border-radius: 10px;
   margin-bottom: 20px;
   font-size: 1.1rem;
 }
 #keyModal button {
   padding: 12px 20px;
   font-size: 1.1rem;
   border-radius: 10px;
 }
</style>
</head>
<body>
<div id="keyModal">
  <h2>ChatGPT API Key を入力してください</h2>
  <input id="apiKeyInput" placeholder="sk-..." />
  <button onclick="saveKey()">保存して開始</button>
</div>
<div id="container" onclick="captureAndDescribe()">
  <video id="camera" autoplay playsinline></video>
  <div id="overlay">画面をタッチして風景を解析します…</div>
</div>
<script>
let apiKey = "";
let stream;
let speech = window.speechSynthesis;

async function loadKey() {
  const db = await openDB();
  const tx = db.transaction('kv', 'readonly');
  const store = tx.objectStore('kv');
  const req = store.get('apiKey');
  const key = await new Promise(resolve => {
    req.onsuccess = () => resolve(req.result);
    req.onerror = () => resolve(null);
  });
  if (key) {
    apiKey = key;
    document.getElementById('keyModal').style.display = 'none';
    startCamera();
  }
}

async function saveKey() {
  const v = document.getElementById('apiKeyInput').value.trim();
  if (!v) return;
  const db = await openDB();
  const tx = db.transaction('kv', 'readwrite');
  const store = tx.objectStore('kv');
  await new Promise(resolve => {
    const req = store.put(v, 'apiKey');
    req.onsuccess = () => resolve();
    req.onerror = () => resolve();
  });
  apiKey = v;
  document.getElementById('keyModal').style.display = 'none';
  startCamera();
}

function openDB() {
  return new Promise((resolve, reject)=>{
    const req = indexedDB.open('visionDB',1);
    req.onupgradeneeded = ()=>{
      const db = req.result;
      if (!db.objectStoreNames.contains('kv')) db.createObjectStore('kv');
    };
    req.onsuccess = ()=> resolve(req.result);
    req.onerror = ()=> reject(req.error);
  });
}

async function startCamera() {
  try {
    // 背面カメラ（environment）を優先して取得
    stream = await navigator.mediaDevices.getUserMedia({
      video: {
        facingMode: { ideal: "environment" }
      }
    });
  } catch (e) {
    console.warn("背面カメラ取得に失敗したため、デフォルトカメラを使用します:", e);
    // 失敗した場合は従来通り（フォールバック）
    stream = await navigator.mediaDevices.getUserMedia({ video: true });
  }

  const video = document.getElementById('camera');
  video.srcObject = stream;
}

async function captureAndDescribe() {
  if (!apiKey) {
    speak("まず ChatGPT の API キーを設定してください。");
    return;
  }

  const video = document.getElementById("camera");
  const overlay = document.getElementById("overlay");

  // まだビデオが初期化されてない場合のガード
  if (!video.videoWidth || !video.videoHeight) {
    overlay.textContent = "カメラの準備中です…もう一度タップしてください。";
    speak("カメラの準備中です。少し待ってからもう一度タップしてください。");
    return;
  }

  // 画像キャプチャ
  const canvas = document.createElement("canvas");
  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;
  const ctx = canvas.getContext("2d");
  ctx.drawImage(video, 0, 0);

  // data:image/jpeg;base64,... 形式の Data URL
  const dataUrl = canvas.toDataURL("image/jpeg");

  overlay.textContent = "解析中です。少しお待ちください…";
  speak("周りの様子を解析します。少しお待ちください。");

  try {
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${apiKey}`
      },
      body: JSON.stringify({
        model: "gpt-4o-mini",
        messages: [
          {
            role: "system",
            content: "あなたは視覚障害者向けに、周囲の状況を丁寧で優しい日本語で説明するアシスタントです。難しい言葉はできるだけ避けて、距離感や位置関係もわかりやすく伝えてください。"
          },
          {
            role: "user",
            content: [
              {
                type: "text",
                text: "この画像に写っている光景を、視覚障害者向けにわかりやすく説明してください。"
              },
              {
                type: "image_url",
                image_url: {
                  // ★ここが重要：オブジェクト形式で url を渡す
                  url: dataUrl
                }
              }
            ]
          }
        ],
        max_tokens: 400
      })
    });

    if (!response.ok) {
      // ここで 400 の詳細をコンソールに出しておくと原因調査しやすい
      const errorText = await response.text();
      console.error("OpenAI API error:", response.status, errorText);

      overlay.textContent = "情報を取得できませんでした。（エラー " + response.status + "）";
      speak("情報を取得できませんでした。あとでもう一度試してください。");
      return;
    }

    const json = await response.json();
    const text =
      (json.choices &&
        json.choices[0] &&
        json.choices[0].message &&
        json.choices[0].message.content) ||
      "情報を取得できませんでした。";

    overlay.textContent = text;
    speak(text);
  } catch (e) {
    console.error(e);
    overlay.textContent = "通信エラーが発生しました。ネットワークを確認してください。";
    speak("通信エラーが発生しました。ネットワーク環境を確認してください。");
  }
}


function speak(text) {
  if (!speech) return;
  speech.cancel();
  const ut = new SpeechSynthesisUtterance(text);
  ut.lang = 'ja-JP';
  speech.speak(ut);
}

loadKey();
</script>
</body>
</html>
